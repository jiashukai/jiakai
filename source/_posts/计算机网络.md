---
title: 计算机网络
date: 2019-01-07T21:17:17.000Z
tags: null
---

# 1.计算机网络分为哪几层

## OSI模型有7层，如果是TCP/IP协议簇，则有4层：

OSI模型中从下往上依次是：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。 TCP/IP协议簇从下往上依次是：网络接口层，网际层IP，运输层（TCP或UDP），应用层。 这里简要介绍一下各层的主要作用：

### （1）应用层

应用层是体系结构中的最高层，应用层直接为用户的应用进程提供服务。这里的进程就是指正在运行的程序。在因特网中应用层协议很多，如支持万维网的HTTP协议，支持电子邮件的SMTP协议，支持文件传送的FTP协议等等

### （2）运输层

运输层的任务就是负责向两个主机中进程之间的通信提供服务。由于一个主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程同时可同时使用下面运输层的服务，分用则是运输层把收到的信息分别交付给上面应用层中相应的进程。 运输层主要使用一下两种协议：

#### 1.传输控制协议---面向连接的，数据传输的单位是报文段，能够提供可靠的交付

#### 2.用户数据包协议UDP---无连接的，数据传输的单位使用户数据报，不保证可靠地交付，只能提供"尽最大努力交付"。

### (3) 网络层

网络层负责为分组交换网上的不同主机提供通信服务。在发送数据时，网络层把运输层产生的报文段或则用户数据报封装成分组或包进行传送。在TCP/IPti体系中，由于网络层使用IP协议，因此分组也叫作IP数据报，或简称为数据报。

网络层的另一个任务就是要选择合适的路由，使源主机运输层所传下来的分组，能够通过网络层的路由器找到目的主机。

网络层主要的协议是无连接的网际IP协议和许多路由选择协议。

### （4）数据链路层

我们知道两个主机之间的数据传输，总是在一段一段的链路上传输的，也就是说，在两个相邻节点之间传送数据是直接传送的。这时就需要使用专门的链路层的协议。在两个相邻的节点之间船速数据时，数据链路层将网络层交下来的IP数据报组装成帧，在两个相邻的节点之间的链路上"透明"地传送帧中的数据。每一帧包括数据和必要的控制信息。

### （5）物理层

在物理层上所传数据的单位是比特。物理层的任务就是透明地传送比特流

# 2.TCP和UDP有什么区别，各自的使用场景以及那些应用层协议使用使用了TCP与UDP

## TCP与UDP的区别：

```
01.TCP是面向连接的传输控制协议，而UDP提供了无连接的数据报服务
02.TCP具有高可靠性，确保传输数据的正确性，不出现丢失或乱序；UDP在数据传输前不建立连接，不对数据报进行检查与修改，无须等待对方的应答，所以会出现分组丢失，重复，乱序，应用程序需要负责传输可靠性方面的工作
03.UDP具有较好的实时性，工作效率较TCP协议高
04.UDP结构段比TCP的结构段简单，因此网路开销也小
```

## 各自的使用场景

```
TCP：对效率要求相对低，但对准确性要求相对高；或则是要求有连接的场景
UDP：对效率要求相对较高，对准确性要求相对低的场景
```

## TCP与UDP的应用（应用层协议）

```
TCP：电子邮件（SMTP），远程终端接入（TELNET），万维网（HTTP），文件传送（FTP）
UDP：名字转换（DNS），文件传送（TFTP）路由选择协议（RIP），IP地址配置（BOOTP，DHCP），网络管理（SNMP），远程文件服务器（NFS），IP（专用协议），流式多媒体电话（专用协议），多播（IGMP）
```

## TCP与UDP的优缺点：

```
1.TCP
  优点：可靠，稳定。
      TCP的可靠性体现在传输数据前，三次握手建立连接（四次挥手断开连接），并在数据传递时，有确认，窗口，重传，拥塞控制机制，数据传完之后断开连接来节省系统资源。
  缺点：慢，效率比较低，占用系统资源，容易被攻击。 在传输数据之前建立连接，这样会消耗时间，而且在消息传递时，确认机制，重传机制和拥塞机制都会消耗大量的时间，而且在每台设备上维护所有的传输连接。而且没一个连接都会占用系统的CPU，内存等软硬件资源。而且TCP的连接机制，三次握手机制导致TCP容易被人利用，实现DOS，DDOS攻击。
2.UDP
  优点：快，比TCP安全
      UDP没有TCP的握手，确认窗口，重传，拥塞机制。UDP是一个无状态的传输机制，所以在传输数据时非常快。UDP没有TCP这些机制，相应被利用的漏洞就少一点。但是UDP的攻击也是存在的，比如UDP的flood攻击
  缺点：不可靠，不稳定
      因为UDP没有TCP的那些可靠机制，在网络质量不好的时候容易发生丢包
```

# 3.滑动窗口协议

```
这里我们假定数据只在一个方向上进行，即A发送数据，B给出确认。这样讨论好处是限于两个窗口，即A的发送窗口和接收方B的接受窗口，这样使问题简化。
```

TCP的滑动窗口是以字节为单位的如下图我们假定A收到了B发来的确认报文段，其中窗口是20（字节），而确认号是31（这表明B期望收到的下一个序号是31，而序号30为止的数据已经收到了），根据这两个数据，A就构造出自己的发送窗口如下图： ![Image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/滑动窗口1.png)

```
我們先讨论发送方A的发送窗口。发送窗口表示：在没有收到B的确认的情况下，A可以连续把窗口内的数据都发送出去，凡是已经发送过去的数据，在未收到之前的确认之前必须暂时保留，以便在超时重传时使用。
```

发送窗口里面的序号表示允许发送的序号。窗口越大，发送方基于可以在收到对方确认之前连续发送更多的数据，因而可能获得更高的传输效率。但接受方必须来得及处理这些数据

发送窗口后沿的后面部分表示已发送且已经收到确认。这些数据不需要保留，。而发送窗口前沿前面的部分不允许发送，因为接收方都没有为这部分数据保留临时存放的缓存空间。 发送窗口后沿的变化有两种情况：1.不动 2.前移 发送窗口的前沿也有两种情况：前移和不动。不动对应于两种情况：一是没有收到新的确认，对方通知窗口的大小也不变，二是收到了新的确认但对方通知的窗口缩小了，使得发送窗口前沿正好不动。（发送窗口的前沿有可能因为通知窗口减小太多而后移）；

现在假定A发送了序号为31-41的数据。这时，发送窗口的位置并未改变，但发送窗口内靠后面得11个字节表示已发送但但未收到确认。而发送窗口内靠前面得9个字节是允许发送单还未发送的。如下图： ！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A32.png)

从以上所述可以看出，要描述一个发送窗口的状态需要三个指针：P1，P2，P3\. 小于P1的是已发送并已收到确认的部分，而大于P3的是不允许发送的部分<br>
P3-P1=A的发送窗口<br>
P2-P1=已发送但尚未收到确认的字节数<br>
P3-P2=允许发送但尚未发送的字节数

再看一下B的接受窗口。B的接受窗口的大小是20.在接受窗口外面，到30号为止的数据是已经发送过确认，并且已经交付给主机。因此在B可以不再保留这些数据。接受窗口内的序号（31-50）是允许接收的。在上图中，B收到了序号为32和33的数据。这些数据没有按序到达，因为序号为31的数据没有收到（也许丢失了，也许滞留在网络中的某处）。此时B只能对按序收到的数据中的最高序号给出确认，因此B发送的确认报文段中的确认号仍然是31，而不是32或33.<br>
现在假定B收到了序号为31 的数据，并把序号为31----33的数据交付给主机，然后B删除这些数据。接着把接受窗口向前移动3个序号（如下图）同时给A发送确认，其中窗口值扔为20，但确认号是34.这则表明B已经shoudao序号33为止的数据，B还收到了序号为37,38和40的数据，但这些都没有按序到达，只能先暂存在接受窗口中，A收到确认后，就可以把发送窗口向前活动三个序号，但指针P2不动，可以看出，现在A的发送窗口增大了，可发送的序号范围是42-53.<br>
A在继续发送完序号42-53的数据后，指针P2向前移动和P3重合，但是发送窗口内的序号都已经用完，但还没有再收到确认，由于A的发送窗口已满，可用窗口与已减小到零，因此必须停止发送。请注意，存在下面这种可能性，就是发送窗口内所有的数据都已经正确到达B，B也早已发出了确认。但不幸的是，所有这些确认都滞留在网络中。在没有收到B的确认时，A不能猜测：B是否收到。为了保证可靠传输，A只能认为B还没有收到这些数据。于是，A在经过一段时间后（超时重传）就重传这部分数据，重新设置超时计时器，直到收到B的确认为止。如果A收到的确认号落在发送窗口内，nameA就可以使发送窗口继续向前滑动，并发送新的数据。 ！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A33.png)

前面我们曾给出那这样的概念：发送方的应用程序把字节流写入TCP的发送缓存，接收方的应用进程从TCP的接收缓存在读取字节流。下面我们就进一步讨论前面讲的窗口和缓存的关系。如下图画出了发送发维持的发送缓存和发送窗口，以及接收方维持的接收缓存和接收窗口。这里首先要明确两点。第一，缓存空间和序号都是有限的，并且是循环使用的。第二，由于实际缓存或窗口中的字节数是非常之大的，因此无法再图中把一个个字节的位置标注清楚。这样，图中的一些指针也无法准确画成指向某一字节的位置。

发送缓存用来暂时存放： （1）发送应用程序传送给发送方TCP准备发送的数据 （2）TCP已发出但尚未收到确认的数据 发送窗口有通常只是发送缓存的一部分。已被确认的数据应当从缓存中删除，因此发送缓存和发送窗口的后沿是重合的。发送应用程序最后写入发送缓存的字节减去最后被确认的字节，就是还保留在发送缓存中的被写入的字节数。发送应用程序必须控制写入缓存的速率，不能太快，否则发送你缓存就会没有存放数据的空间。 ！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A34.png)

接受缓存用来暂时存放：<br>
1.按序到达的，但尚未被应用程序读取的数据<br>
2.位按序到达的数据<br>
如果收到的分组检测出现差错，则要丢弃。如果接受应用程序来不及读取收到的数据，则接收缓存最终会被填满，使接收窗口减小到零。反之，如果接受应用程序能够及时从接受缓存中读取收到的数据，接受窗口就可以增大，但最大不能操作接受缓存的大小。

```
根据以上所讨论的，我们还要再强调一下三点。
第一，虽然A的发送窗口是根据B的接受窗口设置的，但在同一时刻，A的发送窗口与并不总是和B的接受窗口一样大。这是因为通过网络传送窗口值需要经历一定的时间滞后（这个时间是不确定的）。另外，发送方还可能根据网络当时的拥塞情况适当减小自己的发送窗口数值。
第二，对于不按序到达的数据应如何处理，TCP标准并无明确的规定。如果接受方把不按序到达的数据一律丢弃，那么接受窗口的管轮将会比较简单，但是这样做对网络资源的利用率不利。TCP通常对不按序到达的数据显示临时存放在接受窗口，等到字节流中所缺少的字节收到后，在按序交付给上层的应用程序。
第三. TCP 要求接受方必须有所积累确认的功能，这样可以减小传输开销，接受方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息顺便捎带上。但请注意两点。第一，接收方不应过分推迟发送确认，否则会导致发送方不必要的重传，这反而浪费了网络的资源。TCP标准规定，确认推迟时间不应超过0.5秒。若收到一连串具有最大长度的报文段，则必须每个一个报文段就要发送一个确认。第二，捎带确认实际上并不经常发生，因为大多说应用程序不同时在两个方向上发送数据。
```

## 超时重传

运输层维护一个超时计时器，当发送了一个数据后超时重传计时器就开始计时，当计时器达到某个值之后仍然没有收到确认，则会触发重传。 超时计时器的重传时间设置多大事很复杂的。<br>
TCP采用一种自适应算法，它记录一个报文的发出时间以及收到相应确认的时间，这两个时间的时间差就是报文的往返时间RTT，TCP保留一个RTT的加权平均间RTTs 新的RTTs=（1-a）_(旧的RTTs)+a_（新的RTT样本）

超时计时器设置的超时重传时间RTO应略大于上面的加权平均往返时间RTTs

# 拥塞避免

在计算机网络中的链路容量，交换节点中的缓存和处理机等，都是网络的资源，在某段时间，弱队网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做拥塞。

```
拥塞控制与流量控制的关系密切，他们之间也存在一些差别。
所谓的拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或则链路不致过载。拥塞控制索要做的都有一个前提，就
```

是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。但是TCP连接的端点只要迟迟不能收到对方的确认信 息，就猜想在当前网络中的某处可能发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处， 也无法知道发生阻塞的具体原因。

```
相反流量控制往往指点对点通信量的控制，是个端到端的问题。流量控制所有做的就是抑制发送端的
发送速率，以便接收端来得及接收。
```

## 几种拥塞控制的方法

### （1）慢开始和拥塞避免

```
发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在
变化。发送方让自己的发送窗口等于拥塞窗口，如果再考虑接收方的接受能力，发送窗口还可能小
于拥塞窗口。
发送方拥塞控制的原则：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组。（只要发送方没有按时收到应当到达的确认报文，就可以猜想网络出现了拥塞）

慢开始算法的思路：当主机开始发送数据时，如果立即把大量的数据字节注入到网络中，name就有可能引起网络拥塞，因为仙子阿并不清楚网络的负荷情况。经验证明，较好的方法是先探测一下，即由小达到逐渐增大发送窗口，也就是说有效达到逐渐增大拥塞窗口的数值。通常在刚开始发送报文段时，先把拥塞窗口cwnd设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使分组注入到网络的速率更加合理。（这样每经过一个传输轮次，拥塞窗口cwnd就加倍）

还要指出，慢开始的“慢”并不是指cwnd的增长速率慢。而是指在TCP开始发送报文段时先设置cwnd
=1,使得发送方在开始时只发送一个报文段，然后再逐渐增大cwnd。这当然比按照大的cwnd一下子把许多报文段突然注入到网络中药“慢得多”。

为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。
当cwnd<ssthresh时 使用上述的慢开始算法。
当cwnd>ssthresh，停止使用慢开始算法而改用拥塞避免算法。
当cwnd=ssthresh时，即可以使用慢开始算法，也可以使用拥塞避免算法。
```

#### 拥塞避免算法

算法思路让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样，拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢的多

无论在慢开始阶段还是拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是有没有按时收到确认），就把慢开始门限ssthresh设置为出现拥塞时发送窗口的一半，然后把拥塞窗口重新设置为1，执行慢开始算法。这样做的目的就是要迅速减小主机发送到网络中的分组，使得发生拥塞的路由器有足够的时间把队列中积压的分组处理完毕。

"拥塞避免"并非完全能够避免拥塞，是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。

### （2）快重传和快恢复

提出这两个算法是基于如下的考虑：<br>
如果发送方设置的超时计时器时限已到但还没有收到确认，那么很可能是网络出现了拥塞，致使报文在网络中的某处被丢弃。这种情况下，TCP马上把拥塞窗口cwnd减小到1，并执行慢开始算法，同时把慢开始门限值ssthresh减半。这是不使用重传的情况。<br>
下面再看看重传的情况

快输重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方尽早知道有报文没有到达对方）而不要等待自己发送数据时才进行捎带确认，如下图。接收方收到了M1和M2后都分别发送了确认，现在假定接收方没有收到M3但接着收到了M4。显然接收方不能确认M4，因为m4是收到的失序报文段。根据可靠传输的原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。但是按照快速重传算法的规定，接收方应及时发送对M2的重复确认，这样可以让发送方尽早知道报文段M3没有到达接收方。发送方接着发送M5和M6。接收方收到了也还要再次发出对M2的重复确认。这样，发送方共收到了4次对M2的重复确认，其中后三个都是重复确认。快速重传算法规定，发送方只要一连收到三重复个确认就应当立即重传对方尚未收到的报文段M3，而不必继续等待为M3设置的超时计时器到期。由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络的吞吐量提高约20%。 ！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/%E5%BF%AB%E9%87%8D%E4%BC%A0.png)

与快重传配合使用的还有快恢复算法，其过程有以下两个特点： （1）当发送方连续收到三个重复确认时，就执行"乘法减小"算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意，接下去不执行慢开始算法。<br>
（2）由于发送方现在认为网络很可能没有发生拥塞（如果网络发生了严重的拥塞，就不会一连有好几个报文段连续到达接收方，就不会导致发送方连续发丝用重复确认），因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设为1）而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（"加法增大"），使拥塞窗口缓慢线性增大。 下图给出了快重传和快恢复的示意图： ！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/%E5%BF%AB%E6%81%A2%E5%A4%8D.png) 请注意也有的快重传实现是把拥塞窗口再增大一下（3个报文段长度），即等于ssthresh+3*MSS。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不在消耗网络的资源而是停留在接收方的缓存中（接收方发出三个重复确认就证明了这个事实），可见现在网络中并不是堆积了分组而是减小了三个分组。因此可以适当把拥塞窗口增大些。

# TCP运输连接管理

## TCP连接的建立

下图画出了TCP建立连接的过程。假定主机A运行的是TCP客户程序，而B运行TCP服务器程序。最初两端的TCP进程都处于CLOSED（关闭）状态，图中主机下面的方框分别是TCP进程所处的状态。请注意，A主动打开连接，而B被动打开连接。

！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png)

B的TCP服务进程先创建传输控制块TCB，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN（收听）状态，等待客户的连接请求。

```
A的TCP客户进程也是首先创建传输控制块TCB，然后向B发送连接请求报文段，这时首部中的同部位SYN=1，同时选择一个初始序列号seq=x。TCP规定，SYN报文段（SYN=1的报文段）不能携带任何数据，但要消耗一个序号。这时TCP客户进程进入SYN-SENT（同步已发送）状态。

B收到连接请求的报文段后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置位1，确认号是ack=x+1，同时也为自己选择一个初始序列号seq=y。请注意这个报文段也不能携带数据，但同样要消耗掉一个序号，这时TCP服务器进程进入SYN-RCVD（同步收到）状态。

TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack=y+1，而自己的序号seq=x+1。TCP规定，ACK报文段可以可以携带数据。但是如果不携带数据则不消耗序号，这种情况下，下一个数据报文段的序号仍是seq=x+1。这时TCP连接已经建立，A进入已建立状态。B收到A的确认后，也进入已建立状态。

上面给出的连接建立过程就叫做三次握手，或三次联络。
```

### 为什么A还要发送一次确认呢？

这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。

### 为什么要采用三次握手？

就是为了防止已失效的连接请求报文段突然传送到了B，假定不采用三次握手，那么只要B发出确认，新的连接就建立了。由于A并没有发出建立连接的请求，因此不会理睬B的确认，也不会向B发送数据。但B确以为新的连接已经建立，并一直等待A发来数据。B的许多资源就这样白白浪费了。

## TCP连接的释放

数据传输结束后，通信的双方都可释放连接。现在A和B都处于连接建立的状态。A的应用进程先向其TCP发出连接释放的报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放的报文段首部的FIN置1，其序号seq=u，它等于前面已传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1（终止等待1）状态，等待B的确认。请注意，TCP规定，FIN报文段即使不携带数据，他也消耗掉一个序号

！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png)

B 收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是V，等于B前面已传送过的数据的最后一个字节的序号加1。然后B就进入关闭等待状态。TCP服务进程这时应通知高层应用进程，因而从A到B这个方向的连接就释放了，这时TCP连接处于半关闭状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，从B到A这个方向的连接并未关闭。这个状态可能会持续一些时间。

A收到B的确认后，就进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。

若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这时B发出的连接释放报文段必须使FIN=1.现假定B的序号为w（在半关闭状态B可能又发送了一些数据）。B还必须重复上次已经发送过的确认号ack=u+1（A到B这个方向的连接已经关闭，没有从A到B发送的数据）。这时B就进入最后确认状态，等待A的确认。

A在收到B的连接释放的报文后，必须对此发出确认。在确认报文段中的ACK=1，确认号ack=w+1，而自己的序列号seq=u+1（根据TCP标准，前面发送过的FIN报文段要消耗掉一个序号）。然后进入到TIME-WAIT（时间等待）状态。请注意，现在TCP连接还没有掉。必须经过时间等待计时器（TIME-WAIT）设置的2MSL后，A才进入CLOSED状态。时间MSL叫做最长报文段寿命。当A撤销相应的传输控制块TCB后，就结束了这次TCP连接。

### 为什么A要在TIME-WAIT状态必须等待2MSL的时间呢？这有两个理由

第一，为了保证A发送的最后一个ACK报文段能够达到B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN--ACK报文段的确认。B会超时重传这个FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。接着A重传一次确认，2MSL计时器。最后，A和B都正常进入到CLOSED状态。如果A在TIME_WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，name久无法收到B重传的FIN+ACK报文段，因而也不会在发送一次确认报文段。这样，B就无法按照正常步骤进入CLOSED状态。<br>
第二，防止前面提到的"已失效的连接请求报文段"出现在本连接中。A在发送完最后一个ACK报文段后，再经过2MSL，就可以是本连接持续的时间内所产生的所有报文都从网络中消失。这样就可以是下一个连接中不会出现旧的连接请求报文段。

B收到A的确认后就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次TCP连接。

# 域名到IP地址的解析过程


当某一个应用进程需要把主机名解析为IP地址时，该应用进程就调用解析程序，并成为DNS的一个客户，把带解析的域名放在DNS请求报文中，以UDP用户数据报方式发给本地域名服务器（使用UDP是为了减小开销）。本地域名服务器在查找域名后，把对应的IP地址方在回答报文中返回。应用进程获得目的主机的IP地址后即可进行通信。

若本地域名服务器不能回答该请求，则此域名服务器就暂时成为DNS中的拎一个客户，并向其他域名服务器发出查询请求。这种过程直至找到能回答该域名请求的域名服务器为止。

DNS即不规定一个域名需要包含多少个下级域名，也不规定每一级的域名代表什么意思。各级域名有其上一级的域名管理机构管理，而最高级的顶级域名则由ICANN进行管理。用着红方法可以使没一个域名在整个因特网范围内是唯一的，并且也容易设计出一种查找域名的机制。

当DNS客户向某个根域名服务器进行查询是，因特网上的路由器就能找到离这个DNS客户最近的一个根域名服务器。这样做不仅加快了DNS的查询过程，也更加合理的利用因特网的资源。

在许多情况下，根域名服务器并不直接把带查询的域名直接转换成IP地址（根域名服务器也没有存放这种信息），而是告诉本地服务器下一步应当找哪一些顶级域名服务器进行查询。

###  下面简单讨论一下域名的解析过程，这里要注意两点.
第一，主机向本地域名服务器的查询一般都是采用 递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询域名的IP地址，name本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文，而不是让该主机自己进行下一步查询。因此，递归查询返回的查询结果或则是索要查询的IP地址，或则是报错，表示无法查询到所需的IP地址。
第二，本地域名服务器向根域名服务器的查询通常是采用 迭代查询的特点是这样的：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出索要查询的IP地址，要么告诉本地域名服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地域名服务器进行后续查询。根域名服务器通常是通常把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器再收到本地域名服务器的额查询请求后，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应当向哪一个权限域名服务器进行查询。本地域名服务器就这样进行迭代查询。最后你知道配所要了解的域名的IP地址，然后把这和结果返回给发起查询的主机。当然本地域名服务器采用递归查询
# 文件传送协议
  FTP          
文件传输协议FTP只提供文件传送的一些基本服务，它使用TCP可靠的运输服务。FTP的主要功能是减少或则消除在不同操作系统下处理文件的不兼容性。
FTP使用客户服务器方式。一个FTP服务进程课同时为多个客户进程提供服务。FTP的服务进程有两部分组成：一个主进程，负责接收新的请求；另外有若干个从属进程，负责处理单个请求。         
主进程的工作步骤如下：
（1）打开熟知端口（端口号为21），使客户进程能够连接上
（2）等待客户进程发出连接请求                     
（3）启动从属进程来处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后即终止，但从属进程在运行期间根据需要还可能穿件其他一些子进程。              
（4）回到等待状态，继续接受其他客户进程发来的请求。主进程与从属进程的处理是并发进行的。                   
TFTP协议：简单的文件传输协议          
TFTP的主要优点有两个：                    
第一，TFTP可用于UDP环境
第二，TFTP代码所占的内存较小                     
特点：
（1）每次传送的数据报文中有512字节的数据，但最后一次课不住512字节
（2）数据报文按序编号，从1开始                         
（3）支持ASCII码或二进制传送            
（4）可对文件进行读或则写
（5）使用很贱的首部
#万维网
（1）万维网使用同一资源定位符URL来标志万维网上的各种文档，并使没一个文档在整个因特网的范围内具有唯一的标识符URL
（2）万维网客户程序与万维网服务器程序之间的交互遵守严格的协议，这就是草文本传输协议HTTP，它是一个应用层协议，它使用TCP连接进行可靠的传送
（3）万维网使用超文本标记语言HTML，使得万维网页面的设计只可以很方便地用链接从本页面的某处连接到因特网上的任何一个万维网页面，并且能够在自己的主机屏幕上将这些页面显示出来。

### URL：
<协议>：//<主机>：<端口>/<路径>
第一部分写<协议>是指使用什么协议来获取该万维网文档。现在最常用的协议就是http，其次是ftp。协议后面的：//不能省略，它右边的第二部分<主机>，指出这个万维网文档时在哪一个主机上。这里的主机就是指该主机在因特网上的域名，在后面是第三和第四部分<端口>和<路径>，有时可省略
##HTTP协议
HTTP协议的默认端口号是：80
#什么是https协议
HTTPS是在HTTP上建立SSL加密层，并对传输数据进行加密，是HTTP协议的安全版。HTTPS主要作用是：
（1）对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全；
（2）对网站服务器进行身份认证

TLS/SSL全称安全传输层协议Transport Layer Security, 是介于TCP和HTTP之间的一层安全协议，不影响原有的TCP协议和HTTP协议，所以使用HTTPS基本上不需要对HTTP页面进行太多的改造
！[image text](https://github.com/jiashukai/jiakai/blob/master/source/_posts/pictures/HTTPS.png)

hhttps使用了哪些密钥？
对称密钥和非对称密钥:
对称密钥：加密和解密都用同一种密钥     非对称密钥：加密和解密使用不同的密钥
